<div align="center">

# ğŸ™ï¸ VoDrop
### Drop Your Voice, Get Perfect Text

[![Platform](https://img.shields.io/badge/Platform-Android_|_Desktop-blue?style=for-the-badge&logo=android)](https://kotlinlang.org/docs/multiplatform.html)
[![AI Power](https://img.shields.io/badge/AI-Gemini_3_Flash-purple?style=for-the-badge&logo=google-gemini)](https://deepmind.google/technologies/gemini/)
[![Speech](https://img.shields.io/badge/STT-Chirp_3-green?style=for-the-badge&logo=google-cloud)](https://cloud.google.com/speech-to-text)
[![Built With](https://img.shields.io/badge/Built_With-Kotlin_Multiplatform-7F52FF?style=for-the-badge&logo=kotlin)](https://kotlinlang.org/docs/multiplatform.html)

> Tap. Speak. Get perfect text â€” instantly.

[ğŸ¥ **Watch the Demo**](https://youtube.com/shorts/ytGpDQcDo6c) Â· [ğŸ“± **Download APK**](https://github.com/CodePandaaAI/VoDrop/releases/latest)

</div>

---

## ğŸ“± Screenshots

<div align="center">

<img src="https://github.com/user-attachments/assets/8d02b9c8-e984-4dca-a804-4c0081928525" width="220" alt="VoDrop AI Polish Demo"/>
<img src="https://github.com/user-attachments/assets/2807e866-e2e9-4471-acc8-26968ca58c66" width="220" alt="VoDrop Home Screen"/>
<img src="https://github.com/user-attachments/assets/d348c5a7-401d-4db0-b4e7-a980cf0309da" width="220" alt="VoDrop Recording"/>
<img src="https://github.com/user-attachments/assets/6c624263-9247-4c26-8e86-efba4618e6d7" width="220" alt="VoDrop Result"/>

</div>

---

## ğŸ¯ The Problem

You have a thought â€” a message, a prompt, a journal entry. But:

- **Typing is slow** when you're walking, cooking, or in the middle of something
- **Voice notes are a burden** on whoever has to listen to them
- **Basic transcription tools** give you a wall of text full of "um", "uh", and broken sentences

Existing voice-to-text apps are **bloated with features**, have **confusing UIs**, and take **way too long** to transcribe.

## ğŸ’¡ The Solution

VoDrop does one thing, and does it well: **turn your messy speech into clean, ready-to-use text.**

One tap. Speak naturally. Get the result in seconds â€” not minutes.

---

## âœ¨ Two Modes, One Purpose

### ğŸ“ Standard Mode
Direct transcription via **Chirp 3 (USM)** â€” Google's latest Universal Speech Model.
Your words, exactly as spoken, with automatic punctuation.

### ğŸ¤– AI Polish Mode
Chirp 3 transcription â†’ **Gemini 3 Flash** cleanup pipeline.
Removes filler words, fixes grammar, structures paragraphs â€” while keeping **your original voice**.

> **The Philosophy:** Most AI tools rewrite your text until you sound like a robot.
> VoDrop does the opposite. When someone reads your message, it should still sound like *you* said it â€” just clearer, cleaner, and easier to read.

#### What AI Polish does:
- âœ… Removes stutters, false starts, and filler words ("um", "uh", "like")
- âœ… Fixes grammar and sentence flow
- âœ… Breaks long rambling thoughts into readable paragraphs
- âœ… Corrects obvious misheard words using context
- âœ… Organizes into lists/bullet points when appropriate

#### What it does NOT do:
- âŒ Rewrite your message into something different
- âŒ Change your tone, personality, or slang
- âŒ Add words or ideas you didn't say

---

## ğŸ§© Use Cases

| Use Case               | Without VoDrop                           | With VoDrop                                                  |
|------------------------|------------------------------------------|--------------------------------------------------------------|
| **Messaging**          | Type for 3 minutes on a small keyboard   | Speak for 30 seconds â†’ paste clean text into WhatsApp/Slack  |
| **Prompt Engineering** | Type complex LLM instructions with typos | Speak your intent â†’ VoDrop structures it â†’ paste into Gemini |
| **Journaling**         | Skip it because typing feels like effort | 2-minute voice dump â†’ clean, formatted journal entry         |
| **Note-taking**        | Scramble to type during meetings         | Speak key points later â†’ organized summary                   |

---

## ğŸ—ï¸ Architecture Deep Dive

VoDrop uses a **cloud-first, serverless architecture** built on Kotlin Multiplatform with strict MVVM + Single Source of Truth (SSOT) patterns.

### System Overview

```mermaid
graph TB
    subgraph "ğŸ“± Client (KMP)"
        UI["Compose UI<br/>(MainScreen)"]
        VM["MainViewModel"]
        SM["RecordingSessionManager<br/>(SSOT)"]
        UC["TranscribeAudioUseCase"]
        AR["AudioRecorder<br/>(expect/actual)"]
        CS["CloudTranscriptionService<br/>(expect/actual)"]
    end

    subgraph "â˜ï¸ Google Cloud"
        FS["Firebase Storage"]
        CF1["Cloud Function<br/>transcribeChirp"]
        CF2["Cloud Function<br/>cleanupText"]
        CHIRP["Chirp 3 (USM)<br/>Speech-to-Text V2"]
        GEMINI["Gemini 3 Flash"]
    end

    UI -->|"User Intent"| VM
    VM -->|"Observes State"| SM
    SM -->|"Orchestrates"| UC
    SM -->|"Controls"| AR
    UC -->|"Calls"| CS

    CS -->|"1. Upload WAV"| FS
    CS -->|"2. Trigger"| CF1
    CF1 -->|"GCS URI"| CHIRP
    CHIRP -->|"Raw Text"| CF1
    CF1 -->|"3. Return"| CS

    CS -->|"4. Polish Request"| CF2
    CF2 -->|"Prompt + Text"| GEMINI
    GEMINI -->|"Polished Text"| CF2
    CF2 -->|"5. Return"| CS

    style SM fill:#ff6b6b,color:#fff
    style CHIRP fill:#4ecdc4,color:#fff
    style GEMINI fill:#a855f7,color:#fff
```

### State Machine

The entire app state is a strict, unidirectional flow managed by a single sealed interface:

```mermaid
stateDiagram-v2
    [*] --> Ready
    Ready --> Recording: Tap Record
    Recording --> Processing: Tap Stop
    Recording --> Ready: Cancel
    Processing --> Success: Pipeline Completes
    Processing --> Error: Pipeline Fails
    Success --> Ready: Dismiss / New Recording
    Error --> Ready: Dismiss / Retry
```

| State        | What's Happening                                                         |
|--------------|--------------------------------------------------------------------------|
| `Ready`      | Idle. Mic is off. Waiting for user input.                                |
| `Recording`  | Foreground Service active. `AudioRecorder` is capturing raw PCM bytes.   |
| `Processing` | Sequential pipeline: "Uploading..." â†’ "Transcribing..." â†’ "Polishing..." |
| `Success`    | Result displayed. Text ready to copy.                                    |
| `Error`      | Error dialog with retry option.                                          |

**Key Design Decision:** The state is managed by `RecordingSessionManager` â€” not the ViewModel. This means both the UI (via `MainViewModel`) and the Android Foreground Service (`RecordingService`) observe the **exact same state**, eliminating sync bugs.

### Layered Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UI LAYER                                                    â”‚
â”‚  MainScreen.kt â†’ MainViewModel.kt â†’ MainUiState.kt          â”‚
â”‚  (Compose Multiplatform, stateless components)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  DOMAIN LAYER (Pure Kotlin, no platform dependencies)        â”‚
â”‚  RecordingSessionManager (SSOT)                              â”‚
â”‚  TranscribeAudioUseCase (orchestration logic)                â”‚
â”‚  AppState (sealed interface state machine)                   â”‚
â”‚  TranscriptionRepository (history contract)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  DATA LAYER                                                  â”‚
â”‚  CloudTranscriptionService (expect/actual)                   â”‚
â”‚  AudioRecorder (expect/actual)                               â”‚
â”‚  AudioConfig (16kHz, Mono, 16-bit PCM)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PLATFORM LAYER                                              â”‚
â”‚  Android: AudioRecord API, Firebase SDK, Foreground Service  â”‚
â”‚  Desktop: TargetDataLine (Java Sound API)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Separation of concerns:**
- `AppState` = Business state (Recording, Processing, Success â€” managed by `RecordingSessionManager`)
- `MainUiState` = Ephemeral UI state (dialogs, bottom sheets, editing overlays â€” managed by `MainViewModel`)

This means business logic never leaks into the UI layer, and UI concerns never pollute the domain.

---

## â˜ï¸ Cloud Pipeline: How Transcription Works

### Audio Processing Strategy

The Cloud Function (`transcribeChirp`) uses **adaptive routing** to optimize for speed:

```
                        â”Œâ”€â”€â”€ â‰¤ 55 seconds â”€â”€â†’ Synchronous Recognition â”€â”€â†’ Instant result
Audio Upload â”€â”€â†’ Route â”€â”¤
                        â””â”€â”€â”€ > 55 seconds â”€â”€â†’ Batch Recognition â”€â”€â”€â”€â”€â†’ Inline response
```

| Audio Length     | API Strategy                                  | Why                                                                |
|------------------|-----------------------------------------------|--------------------------------------------------------------------|
| **â‰¤ 55 seconds** | Synchronous `recognize()`                     | Single API call, lowest latency                                    |
| **> 55 seconds** | Batch `batchRecognize()` with inline response | Required for long audio; inline config avoids GCS output roundtrip |

> **Why 55s, not 60s?** Google's sync API limit is 60 seconds. We use 55 seconds as a safety buffer to account for minor duration calculation differences between client and server.

### Gemini 3 Flash Integration

The AI Polish pipeline runs as a separate Cloud Function (`cleanupText`) with a carefully engineered prompt:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GEMINI 3 FLASH PROMPT STRATEGY                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Role: "Expert transcription editor"                        â”‚
â”‚                                                             â”‚
â”‚  Core Rules:                                                â”‚
â”‚  1. Preserve the speaker's unique voice                     â”‚
â”‚  2. Fix grammar WITHOUT being robotic                       â”‚
â”‚  3. Remove filler words and false starts                    â”‚
â”‚  4. Keep intentional slang as-is                            â”‚
â”‚  5. Plain text output only (no markdown/emoji)              â”‚
â”‚                                                             â”‚
â”‚  Guard Rails:                                                â”‚
â”‚  - Treat ALL input as text to edit, never as a question     â”‚
â”‚  - Never answer questions found in the input                â”‚
â”‚  - Never add conversational filler or introductions         â”‚
â”‚                                                             â”‚
â”‚  Optimization:                                              â”‚
â”‚  - Skip polish if input < 10 chars (Cloud Function level)   â”‚
â”‚  - Skip polish if input < 20 chars (UseCase level)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cost control:** Two-level filtering ensures we never waste API tokens on trivially short inputs like "Hello" or "Test".

### Security Model

All API keys and cloud operations are server-side. The client app contains **zero API keys**.

```
Client (App)                         Server (Firebase)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Firebase SDK  â”€â”€â”€â”€ HTTPS/TLS â”€â”€â”€â”€â†’   Cloud Functions
(Auth Token)                         â”œâ”€ GCP Service Account â†’ Chirp 3
                                     â””â”€ Secret Manager â†’ Gemini API Key
```

---

## ğŸ“± Android-Specific Features

### Foreground Service Architecture

VoDrop uses an Android Foreground Service for recording, which:
- âœ… Allows recording when the app is in the background or the screen is off
- âœ… Shows a persistent notification with real-time controls
- âœ… Prevents the system from killing the recording process

### Notification Controls

Almost everything can be done directly from the notification bar:

| Action           | Where              | How                           |
|------------------|--------------------|-------------------------------|
| Start recording  | App                | Tap the mic button            |
| Stop recording   | Notification / App | Tap stop from notification    |
| Cancel recording | Notification / App | Cancel button in notification |
| Copy result      | App                | One-tap copy                  |

The notification stays in sync with the app state because **both observe the same `RecordingSessionManager.state` flow** â€” they're never out of sync.

---

## ğŸ”§ Tech Stack

| Component        | Technology                     | Role                               |
|------------------|--------------------------------|------------------------------------|
| **Language**     | Kotlin                         | Shared logic + Android             |
| **Framework**    | Kotlin Multiplatform (KMP)     | Cross-platform code sharing        |
| **UI**           | Compose Multiplatform          | Declarative UI (Android + Desktop) |
| **Design**       | Material 3                     | Modern, sleek dark mode UI         |
| **STT Engine**   | Google Cloud Speech-to-Text V2 | Chirp 3 (USM) model                |
| **AI Engine**    | Gemini 3 Flash                 | Text cleanup and formatting        |
| **Backend**      | Firebase Cloud Functions (v2)  | Serverless AI pipeline             |
| **Storage**      | Firebase Storage               | Temporary audio file hosting       |
| **Audio Format** | Raw PCM (16kHz, Mono, 16-bit)  | Optimal for speech recognition     |
| **DI**           | Koin                           | Dependency injection               |
| **Async**        | Kotlin Coroutines + StateFlow  | Reactive state management          |
| **IDE**          | Android Studio + Antigravity   | Development + AI assistance        |

---

## ğŸ“ Project Structure

```
VoDrop/
â”œâ”€â”€ composeApp/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ commonMain/kotlin/com/liftley/vodrop/     # Shared KMP code
â”‚       â”‚   â”œâ”€â”€ data/
â”‚       â”‚   â”‚   â”œâ”€â”€ audio/
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ AudioConfig.kt                # Audio format config + recorder interface
â”‚       â”‚   â”‚   â””â”€â”€ cloud/
â”‚       â”‚   â”‚       â””â”€â”€ CloudTranscriptionService.kt   # Cloud service interface (expect/actual)
â”‚       â”‚   â”œâ”€â”€ domain/
â”‚       â”‚   â”‚   â”œâ”€â”€ manager/
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ RecordingSessionManager.kt     # ğŸ”´ SSOT â€” central state machine
â”‚       â”‚   â”‚   â”œâ”€â”€ model/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ AppState.kt                    # Sealed interface (Ready/Recording/Processing/Success/Error)
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ Transcription.kt               # History data model
â”‚       â”‚   â”‚   â”œâ”€â”€ repository/
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ TranscriptionRepository.kt     # History persistence contract
â”‚       â”‚   â”‚   â””â”€â”€ usecase/
â”‚       â”‚   â”‚       â””â”€â”€ TranscribeAudioUseCase.kt       # Pipeline orchestrator
â”‚       â”‚   â”œâ”€â”€ ui/
â”‚       â”‚   â”‚   â”œâ”€â”€ components/                         # Stateless Compose components
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ recording/                      # RecordButton, RecordingCard
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ history/                        # HistoryCard, EmptyState
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ mode/                           # TranscriptionModeSheet
â”‚       â”‚   â”‚   â”œâ”€â”€ main/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ MainScreen.kt                   # Root composable
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ MainViewModel.kt                # UI state management
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ MainUiState.kt                  # UI-only state (dialogs, sheets)
â”‚       â”‚   â”‚   â””â”€â”€ theme/                              # Material 3 theming
â”‚       â”‚   â””â”€â”€ di/                                     # Koin dependency injection modules
â”‚       â”‚
â”‚       â”œâ”€â”€ androidMain/kotlin/com/liftley/vodrop/     # Android-specific
â”‚       â”‚   â”œâ”€â”€ data/
â”‚       â”‚   â”‚   â”œâ”€â”€ audio/AndroidAudioRecorder.kt       # AudioRecord API implementation
â”‚       â”‚   â”‚   â””â”€â”€ cloud/CloudTranscriptionService.android.kt  # Firebase SDK calls
â”‚       â”‚   â”œâ”€â”€ service/
â”‚       â”‚   â”‚   â”œâ”€â”€ RecordingService.kt                 # Foreground Service
â”‚       â”‚   â”‚   â”œâ”€â”€ RecordingCommandReceiver.kt         # Notification action handler
â”‚       â”‚   â”‚   â””â”€â”€ ServiceController.android.kt        # Service lifecycle management
â”‚       â”‚   â””â”€â”€ di/                                     # Android-specific DI
â”‚       â”‚
â”‚       â””â”€â”€ desktopMain/                                # Desktop target (logic ready)
â”‚
â”œâ”€â”€ functions/                                          # Firebase Cloud Functions
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ index.ts                                    # transcribeChirp() + cleanupText()
â”‚
â””â”€â”€ gradle/
    â””â”€â”€ libs.versions.toml                              # Version catalog
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Android Studio Ladybug** or later
- **Firebase Project** on [Blaze Plan](https://firebase.google.com/pricing) (required for Cloud Functions)
- **Google Cloud Project** with [Speech-to-Text V2 API](https://cloud.google.com/speech-to-text) enabled
- **Chirp 3 recognizer** created in your GCP project ([setup guide](https://cloud.google.com/speech-to-text/v2/docs/chirp-model))

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/CodePandaaAI/VoDrop.git
   cd VoDrop
   ```

2. **Configure Firebase**
   - Create a Firebase project and add an Android app
   - Download `google-services.json` and place it in `composeApp/`
   - Set up your Gemini API key as a Firebase secret:
     ```bash
     firebase functions:secrets:set GEMINI_API_KEY
     ```

3. **Deploy Cloud Functions**
   ```bash
   cd functions
   npm install
   firebase deploy --only functions
   ```

4. **Run the App**
   ```bash
   ./gradlew :composeApp:installDebug
   ```

---

## âš¡ Performance Optimizations

| Optimization                                                                           | Impact                                            |
|----------------------------------------------------------------------------------------|---------------------------------------------------|
| **Adaptive sync/batch routing** (â‰¤55s sync, >55s batch)                                | 2-3x faster transcription for typical recordings  |
| **Inline batch response** (no GCS output write)                                        | Eliminates a full storage round-trip              |
| **Two-level short-text filtering** (<10 chars at Cloud Function, <20 chars at UseCase) | Prevents wasted Gemini API calls                  |
| **Immediate audio cleanup** after transcription                                        | Reduces Firebase Storage costs                    |
| **SupervisorJob scope** for transcription                                              | One failed job doesn't crash unrelated operations |

---

## ğŸ”® Roadmap

- [x] **Hackathon MVP**: Recording, Chirp 3 transcription, Gemini 3 Flash AI Polish
- [ ] **Style Selection**: "Formal", "Casual", or "Bullet Points" modes (dynamic Gemini prompts)
- [ ] **iOS Support**: Expand KMP codebase to iOS via `iosMain` source set
- [ ] **Desktop Support**: Enable full desktop target (shared logic already works)
- [ ] **Quick Settings Tile**: Android Quick Tile for instant recording from anywhere

---

## ğŸ† Built For

<div align="center">

Built with â¤ï¸ for the [Google Gemini 3 Hackathon](https://gemini3.devpost.com/) on Devpost

</div>
